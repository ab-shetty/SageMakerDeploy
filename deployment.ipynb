{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d6c6857-ca56-4312-83c4-d9e3e016358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5cba05e-badb-4f63-b2ce-26bf5471a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()  # This loads the variables from the .env file\n",
    "hf_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "031859cc-bfdd-47ee-8527-939c644dbc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import sagemaker\n",
    "#import globals as g\n",
    "import requests as req\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "#from utils import get_bucket_name\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker import get_execution_role\n",
    "from huggingface_hub import snapshot_download\n",
    "from sagemaker.huggingface.model import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfde319e-a1b7-4747-a2b5-89bb57f78079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::084375588776:role/service-role/AmazonSageMaker-ExecutionRole-20250210T195773\n",
      "sagemaker bucket: sagemaker-us-west-2-084375588776\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4db64c-f8d4-440b-8c39-47591053587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"1.1.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1992d332-3505-4307-8c7a-6a30d740af95",
   "metadata": {},
   "source": [
    "#### Time to download the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ec31569-a615-4fd1-a2cf-ded33a70f602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353e81f5d66947f2bfd370b0322b720b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30a23d7da5a4a588a2c7bda62a1c41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2191ba901b94006a9727291b753802a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b9f63d9fb94f4798930f20c4fc68dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/2.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3991383f49e2412fb76094bc5b9956d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808a94d57d0245afbc3147f16d52df54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_videollama3.py:   0%|          | 0.00/2.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb4b68a2d4c423c80247fdcb543efb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_videollama3_encoder.py:   0%|          | 0.00/1.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc24d5ec7dd343b29055b92785d73126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694e8db846524ceab17233e0dd9cca46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "image_processing_videollama3.py:   0%|          | 0.00/21.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf3c22c64f346b88f6c103970aff5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf8a9f2771648e9bbf295e59688554a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a07202a4034ecbbdb85977f798908f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fb73f0f0b84c7db644756f2c7a7d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552e0832902a4a69b91f352ecc037166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.29G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733152cdc70b4aab9a1bb6fd632d4d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/72.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6531ecd18c246a0b0f2fb43450cb3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_videollama3.py:   0%|          | 0.00/17.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f1a07153cf46619d9e5ce3d0be3ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_videollama3_encoder.py:   0%|          | 0.00/21.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba9d33f2cd34a7b86b5340604a65c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd93c0260bb4f06a62da1f74daa7e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing_videollama3.py:   0%|          | 0.00/39.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed48f84c9bd45f292342d19fe3bdef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035bb63a14ff4a829d30a3e771ce070f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017c3441ffa14c5a8efec80e55dfe944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4011ad2b25e49fd88be1fca45ba3524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/3.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/sagemaker-user/PerceiveAI/SageMaker/VideoLLaMA3-7B'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "HF_MODEL_ID=\"DAMO-NLP-SG/VideoLLaMA3-7B\"\n",
    "\n",
    "model_dir = Path(HF_MODEL_ID.split(\"/\")[-1])\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "# Download model from Hugging Face into model_dir\n",
    "snapshot_download(HF_MODEL_ID, local_dir=str(model_dir), local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bd669f1-7236-4661-a5e5-8b890727d03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/PerceiveAI/SageMaker\n",
      "0_deploy_llava.ipynb  VideoLLaMA3-7B  deploy_llava.ipynb  deployment.ipynb\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc2901ba-74a0-448d-9c06-174b2440cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./.cache/\n",
      "./.cache/huggingface/\n",
      "./.cache/huggingface/.gitignore\n",
      "./.cache/huggingface/download/\n",
      "./.cache/huggingface/download/.gitattributes.lock\n",
      "./.cache/huggingface/download/.gitattributes.metadata\n",
      "./.cache/huggingface/download/README.md.lock\n",
      "./.cache/huggingface/download/README.md.metadata\n",
      "./.cache/huggingface/download/added_tokens.json.lock\n",
      "./.cache/huggingface/download/added_tokens.json.metadata\n",
      "./.cache/huggingface/download/chat_template.json.lock\n",
      "./.cache/huggingface/download/chat_template.json.metadata\n",
      "./.cache/huggingface/download/config.json.lock\n",
      "./.cache/huggingface/download/config.json.metadata\n",
      "./.cache/huggingface/download/configuration_videollama3.py.lock\n",
      "./.cache/huggingface/download/configuration_videollama3.py.metadata\n",
      "./.cache/huggingface/download/configuration_videollama3_encoder.py.lock\n",
      "./.cache/huggingface/download/configuration_videollama3_encoder.py.metadata\n",
      "./.cache/huggingface/download/generation_config.json.lock\n",
      "./.cache/huggingface/download/generation_config.json.metadata\n",
      "./.cache/huggingface/download/image_processing_videollama3.py.lock\n",
      "./.cache/huggingface/download/image_processing_videollama3.py.metadata\n",
      "./.cache/huggingface/download/merges.txt.lock\n",
      "./.cache/huggingface/download/merges.txt.metadata\n",
      "./.cache/huggingface/download/model-00001-of-00004.safetensors.lock\n",
      "./.cache/huggingface/download/model-00001-of-00004.safetensors.metadata\n",
      "./.cache/huggingface/download/model-00002-of-00004.safetensors.lock\n",
      "./.cache/huggingface/download/model-00002-of-00004.safetensors.metadata\n",
      "./.cache/huggingface/download/model-00003-of-00004.safetensors.lock\n",
      "./.cache/huggingface/download/model-00003-of-00004.safetensors.metadata\n",
      "./.cache/huggingface/download/model-00004-of-00004.safetensors.lock\n",
      "./.cache/huggingface/download/model-00004-of-00004.safetensors.metadata\n",
      "./.cache/huggingface/download/model.safetensors.index.json.lock\n",
      "./.cache/huggingface/download/model.safetensors.index.json.metadata\n",
      "./.cache/huggingface/download/modeling_videollama3.py.lock\n",
      "./.cache/huggingface/download/modeling_videollama3.py.metadata\n",
      "./.cache/huggingface/download/modeling_videollama3_encoder.py.lock\n",
      "./.cache/huggingface/download/modeling_videollama3_encoder.py.metadata\n",
      "./.cache/huggingface/download/preprocessor_config.json.lock\n",
      "./.cache/huggingface/download/preprocessor_config.json.metadata\n",
      "./.cache/huggingface/download/processing_videollama3.py.lock\n",
      "./.cache/huggingface/download/processing_videollama3.py.metadata\n",
      "./.cache/huggingface/download/processor_config.json.lock\n",
      "./.cache/huggingface/download/processor_config.json.metadata\n",
      "./.cache/huggingface/download/special_tokens_map.json.lock\n",
      "./.cache/huggingface/download/special_tokens_map.json.metadata\n",
      "./.cache/huggingface/download/tokenizer_config.json.lock\n",
      "./.cache/huggingface/download/tokenizer_config.json.metadata\n",
      "./.cache/huggingface/download/vocab.json.lock\n",
      "./.cache/huggingface/download/vocab.json.metadata\n",
      "./.gitattributes\n",
      "./README.md\n",
      "./added_tokens.json\n",
      "./chat_template.json\n",
      "./config.json\n",
      "./configuration_videollama3.py\n",
      "./configuration_videollama3_encoder.py\n",
      "./generation_config.json\n",
      "./image_processing_videollama3.py\n",
      "./merges.txt\n",
      "./model-00001-of-00004.safetensors\n",
      "./model-00002-of-00004.safetensors\n",
      "./model-00003-of-00004.safetensors\n",
      "\n",
      "gzip: stdout: No space left on device\n",
      "tar: model.tar.gz: Wrote only 8192 of 10240 bytes\n",
      "tar: Child returned status 1\n",
      "tar: Error is not recoverable: exiting now\n",
      "CPU times: user 6.79 s, sys: 4.7 s, total: 11.5 s\n",
      "Wall time: 18min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!tar cvzf model.tar.gz -C VideoLLaMA3-7B/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54d905c8-d06a-45ad-9a81-32be5773fc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'model.tar.gz': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b29960-2f77-4b57-990c-a969df4162bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739bf61-a142-423e-85dd-de2509ce42e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f437e0c-7c7a-448b-9da3-d99fcb5fa95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_model_uri,      # path to your model and script\n",
    "   role=role,                    # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.28.1\",  # transformers version used\n",
    "   pytorch_version=\"2.0.0\",       # pytorch version used\n",
    "   py_version='py310',            # python version used\n",
    "   model_server_workers=1\n",
    ")\n",
    "\n",
    "# deploy the endpoint endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.xlarge\",\n",
    "    # container_startup_health_check_timeout=600, # increase timeout for large models\n",
    "    # model_data_download_timeout=600, # increase timeout for large models\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
